{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5810245c",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9b70bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 683464 annotations\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "sys.path.append(\"..\")  # Allow imports from src/ \n",
    "\n",
    "# Load your parsed data\n",
    "from src.data.loader import KuzushijiDataset\n",
    "TRAIN_IMG_DIR = Path(\"../data/train\")\n",
    "# Load the pre-processed data\n",
    "train_df = pd.read_parquet(\"../data/train_cleaned.parquet\")\n",
    "print(f\"Loaded {len(train_df)} annotations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba62cb3d",
   "metadata": {},
   "source": [
    "Test 1: Verify Single Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b85b50dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([3, 512, 512])\n",
      "Boxes shape: torch.Size([67, 4])\n",
      "Labels: tensor([12399, 12364, 12356, 12369, 12395, 12395, 12398, 24037, 12371, 19977,\n",
      "        12398, 12420, 12392, 24049, 12418, 12373, 12398, 12398, 19990, 32048,\n",
      "        12381, 20154, 12369, 12428, 12384, 24375, 12398, 12383, 12390, 20467,\n",
      "        26681, 12363, 35559, 12428, 23376, 12434, 21450, 32773, 12378, 36991,\n",
      "        27491, 25991, 12405, 26178, 24605, 12394, 12417, 28014, 12434, 27671,\n",
      "        32887, 32769, 27494, 27005, 12418, 30450, 33509, 33258, 12393, 39080,\n",
      "        12395, 35023, 30067, 24687, 24207, 12375, 12375])\n"
     ]
    }
   ],
   "source": [
    "dataset = KuzushijiDataset(train_df, TRAIN_IMG_DIR)\n",
    "sample = dataset[0]  # First image\n",
    "\n",
    "print(\"Image shape:\", sample['image'].shape)  # Should be [3, 512, 512]\n",
    "print(\"Boxes shape:\", sample['boxes'].shape)  # [N_boxes, 4]\n",
    "print(\"Labels:\", sample['labels'])  # Unicode codes as integers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IAVA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
